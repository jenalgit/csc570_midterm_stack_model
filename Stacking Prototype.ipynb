{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 745 (CNMeM is disabled, CuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import xgboost\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./work_dir/boruta_filtered_train_split.csv\")\n",
    "y=df['y']\n",
    "X=df.drop(['y'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(dropout=0.1, optimizer = 'adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=20, init='glorot_uniform', activation='relu'))\n",
    "    model.add(Dense(10, init='glorot_uniform', activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(10, init='glorot_uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
    "    #sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, nb_epoch=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features = pd.read_csv(\"./work_dir/feature_support.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"./work_dir/my_midterm_test_split.csv\")\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop('y', axis=1)\n",
    "X_test = X_test.ix[:, selected_features['0'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Submission\n",
    "kaggle_test = pd.read_csv(\"./work_dir/my_midterm_kaggle_test.csv\")\n",
    "kaggle_test_selected = kaggle_test.ix[:, selected_features['0'].values]  #trim to the boruta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(nthread=6, n_estimators=300, \n",
    "                            learning_rate = 0.31, max_depth = 16, colsample_bytree = 1)\n",
    "ert = ExtraTreesClassifier(n_jobs=6, random_state=42, n_estimators=500, max_features = 'log2',\n",
    "                           min_samples_split = 1, max_depth =  None, criterion= 'entropy')\n",
    "rfc = RandomForestClassifier(n_jobs=6, random_state=42, n_estimators=500, max_depth= None, \n",
    "                             max_features=  'auto', min_samples_split=  2, criterion=  'entropy')\n",
    "\n",
    "clfs = [xgb, ert, rfc, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf =StratifiedKFold(y, n_folds=n_folds, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blender:\n",
    "    \n",
    "    def __init__(self, n_folds, estimators):\n",
    "        self.n_folds = n_folds\n",
    "        self.estimators = estimators\n",
    "        self.dataset_blend_train = None\n",
    "        self.dataset_blend_test = None\n",
    "        \n",
    "            \n",
    "    def fit_predict(self, X, y, X_submission):\n",
    "        print (\"Creating train and test sets for blending.\")\n",
    "\n",
    "        \n",
    "        dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "        dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "        \n",
    "        skf =StratifiedKFold(y, n_folds=self.n_folds, random_state=42)\n",
    "\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            print(j, clf)\n",
    "            dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "            for i, (train, test) in enumerate(skf):\n",
    "                print (\"Fold\", i)\n",
    "                X_train = X[train]\n",
    "                y_train = y[train]\n",
    "                X_test = X[test]\n",
    "                y_test = y[test]\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "                dataset_blend_train[test, j] = y_submission\n",
    "                dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:, 1]\n",
    "            dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "        print(\"Blending.\")\n",
    "        #from sklearn.linear_model import LogisticRegression\n",
    "        clf = xgboost.XGBClassifier()\n",
    "        clf.fit(dataset_blend_train, y)\n",
    "        y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "        \n",
    "        #print(\"Linear stretch of predictions to [0,1]\")\n",
    "        #y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "        return y_submission\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend = Blender(n_folds=5, estimators=clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.31, max_delta_step=0, max_depth=16,\n",
       "       min_child_weight=1, missing=None, n_estimators=300, nthread=6,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 20)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n",
      "0 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.31, max_delta_step=0, max_depth=16,\n",
      "       min_child_weight=1, missing=None, n_estimators=300, nthread=6,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=1,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=6,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=6,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "3 <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f142ed39748>\n",
      "Fold 0\n",
      "Epoch 1/100\n",
      "3s - loss: 1.1453 - acc: 0.6638\n",
      "Epoch 2/100\n",
      "3s - loss: 0.5162 - acc: 0.7499\n",
      "Epoch 3/100\n",
      "3s - loss: 0.4744 - acc: 0.7812\n",
      "Epoch 4/100\n",
      "3s - loss: 0.4465 - acc: 0.7969\n",
      "Epoch 5/100\n",
      "3s - loss: 0.4105 - acc: 0.8231\n",
      "Epoch 6/100\n",
      "3s - loss: 0.3834 - acc: 0.8394\n",
      "Epoch 7/100\n",
      "3s - loss: 0.3582 - acc: 0.8521\n",
      "Epoch 8/100\n",
      "3s - loss: 0.3423 - acc: 0.8596\n",
      "Epoch 9/100\n",
      "3s - loss: 0.3343 - acc: 0.8628\n",
      "Epoch 10/100\n",
      "3s - loss: 0.3244 - acc: 0.8693\n",
      "Epoch 11/100\n",
      "3s - loss: 0.3182 - acc: 0.8734\n",
      "Epoch 12/100\n",
      "3s - loss: 0.3120 - acc: 0.8764\n",
      "Epoch 13/100\n",
      "3s - loss: 0.3072 - acc: 0.8783\n",
      "Epoch 14/100\n",
      "3s - loss: 0.3064 - acc: 0.8786\n",
      "Epoch 15/100\n",
      "3s - loss: 0.3073 - acc: 0.8778\n",
      "Epoch 16/100\n",
      "3s - loss: 0.2962 - acc: 0.8841\n",
      "Epoch 17/100\n",
      "3s - loss: 0.2982 - acc: 0.8838\n",
      "Epoch 18/100\n",
      "2s - loss: 0.2968 - acc: 0.8858\n",
      "Epoch 19/100\n",
      "2s - loss: 0.2882 - acc: 0.8883\n",
      "Epoch 20/100\n",
      "2s - loss: 0.2854 - acc: 0.8903\n",
      "Epoch 21/100\n",
      "2s - loss: 0.2804 - acc: 0.8930\n",
      "Epoch 22/100\n",
      "2s - loss: 0.2827 - acc: 0.8921\n",
      "Epoch 23/100\n",
      "2s - loss: 0.2865 - acc: 0.8933\n",
      "Epoch 24/100\n",
      "2s - loss: 0.2771 - acc: 0.8954\n",
      "Epoch 25/100\n",
      "2s - loss: 0.2713 - acc: 0.8984\n",
      "Epoch 26/100\n",
      "2s - loss: 0.2693 - acc: 0.8994\n",
      "Epoch 27/100\n",
      "2s - loss: 0.2675 - acc: 0.9016\n",
      "Epoch 28/100\n",
      "2s - loss: 0.2654 - acc: 0.9024\n",
      "Epoch 29/100\n",
      "2s - loss: 0.2660 - acc: 0.9024\n",
      "Epoch 30/100\n",
      "2s - loss: 0.2640 - acc: 0.9017\n",
      "Epoch 31/100\n",
      "2s - loss: 0.2603 - acc: 0.9049\n",
      "Epoch 32/100\n",
      "2s - loss: 0.2548 - acc: 0.9067\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2515 - acc: 0.9080\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2507 - acc: 0.9085\n",
      "Epoch 35/100\n",
      "2s - loss: 0.2466 - acc: 0.9113\n",
      "Epoch 36/100\n",
      "2s - loss: 0.2439 - acc: 0.9123\n",
      "Epoch 37/100\n",
      "2s - loss: 0.2420 - acc: 0.9135\n",
      "Epoch 38/100\n",
      "2s - loss: 0.2424 - acc: 0.9126\n",
      "Epoch 39/100\n",
      "2s - loss: 0.2384 - acc: 0.9149\n",
      "Epoch 40/100\n",
      "2s - loss: 0.2377 - acc: 0.9159\n",
      "Epoch 41/100\n",
      "2s - loss: 0.2353 - acc: 0.9169\n",
      "Epoch 42/100\n",
      "3s - loss: 0.2351 - acc: 0.9169\n",
      "Epoch 43/100\n",
      "2s - loss: 0.2318 - acc: 0.9182\n",
      "Epoch 44/100\n",
      "2s - loss: 0.2313 - acc: 0.9188\n",
      "Epoch 45/100\n",
      "2s - loss: 0.2311 - acc: 0.9195\n",
      "Epoch 46/100\n",
      "2s - loss: 0.2275 - acc: 0.9207\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2299 - acc: 0.9199\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2264 - acc: 0.9199\n",
      "Epoch 49/100\n",
      "2s - loss: 0.2233 - acc: 0.9219\n",
      "Epoch 50/100\n",
      "2s - loss: 0.2228 - acc: 0.9218\n",
      "Epoch 51/100\n",
      "2s - loss: 0.2239 - acc: 0.9220\n",
      "Epoch 52/100\n",
      "2s - loss: 0.2229 - acc: 0.9217\n",
      "Epoch 53/100\n",
      "2s - loss: 0.2204 - acc: 0.9227\n",
      "Epoch 54/100\n",
      "2s - loss: 0.2192 - acc: 0.9239\n",
      "Epoch 55/100\n",
      "2s - loss: 0.2226 - acc: 0.9236\n",
      "Epoch 56/100\n",
      "3s - loss: 0.2251 - acc: 0.9232\n",
      "Epoch 57/100\n",
      "3s - loss: 0.2227 - acc: 0.9238\n",
      "Epoch 58/100\n",
      "2s - loss: 0.2196 - acc: 0.9249\n",
      "Epoch 59/100\n",
      "2s - loss: 0.2190 - acc: 0.9257\n",
      "Epoch 60/100\n",
      "3s - loss: 0.2182 - acc: 0.9267\n",
      "Epoch 61/100\n",
      "3s - loss: 0.2154 - acc: 0.9272\n",
      "Epoch 62/100\n",
      "2s - loss: 0.2169 - acc: 0.9264\n",
      "Epoch 63/100\n",
      "2s - loss: 0.2210 - acc: 0.9254\n",
      "Epoch 64/100\n",
      "2s - loss: 0.2178 - acc: 0.9261\n",
      "Epoch 65/100\n",
      "2s - loss: 0.2162 - acc: 0.9272\n",
      "Epoch 66/100\n",
      "2s - loss: 0.2152 - acc: 0.9277\n",
      "Epoch 67/100\n",
      "2s - loss: 0.2136 - acc: 0.9282\n",
      "Epoch 68/100\n",
      "2s - loss: 0.2145 - acc: 0.9285\n",
      "Epoch 69/100\n",
      "2s - loss: 0.2124 - acc: 0.9282\n",
      "Epoch 70/100\n",
      "2s - loss: 0.2132 - acc: 0.9281\n",
      "Epoch 71/100\n",
      "2s - loss: 0.2123 - acc: 0.9294\n",
      "Epoch 72/100\n",
      "2s - loss: 0.2093 - acc: 0.9297\n",
      "Epoch 73/100\n",
      "2s - loss: 0.2091 - acc: 0.9311\n",
      "Epoch 74/100\n",
      "2s - loss: 0.2114 - acc: 0.9293\n",
      "Epoch 75/100\n",
      "2s - loss: 0.2116 - acc: 0.9297\n",
      "Epoch 76/100\n",
      "2s - loss: 0.2092 - acc: 0.9308\n",
      "Epoch 77/100\n",
      "2s - loss: 0.2092 - acc: 0.9306\n",
      "Epoch 78/100\n",
      "2s - loss: 0.2073 - acc: 0.9316\n",
      "Epoch 79/100\n",
      "2s - loss: 0.2086 - acc: 0.9301\n",
      "Epoch 80/100\n",
      "2s - loss: 0.2081 - acc: 0.9312\n",
      "Epoch 81/100\n",
      "2s - loss: 0.2076 - acc: 0.9308\n",
      "Epoch 82/100\n",
      "2s - loss: 0.2067 - acc: 0.9312\n",
      "Epoch 83/100\n",
      "2s - loss: 0.2069 - acc: 0.9312\n",
      "Epoch 84/100\n",
      "2s - loss: 0.2039 - acc: 0.9330\n",
      "Epoch 85/100\n",
      "2s - loss: 0.2061 - acc: 0.9317\n",
      "Epoch 86/100\n",
      "2s - loss: 0.2039 - acc: 0.9328\n",
      "Epoch 87/100\n",
      "2s - loss: 0.2054 - acc: 0.9322\n",
      "Epoch 88/100\n",
      "2s - loss: 0.2074 - acc: 0.9314\n",
      "Epoch 89/100\n",
      "2s - loss: 0.2048 - acc: 0.9330\n",
      "Epoch 90/100\n",
      "2s - loss: 0.2046 - acc: 0.9327\n",
      "Epoch 91/100\n",
      "2s - loss: 0.2018 - acc: 0.9340\n",
      "Epoch 92/100\n",
      "2s - loss: 0.2032 - acc: 0.9333\n",
      "Epoch 93/100\n",
      "2s - loss: 0.2016 - acc: 0.9337\n",
      "Epoch 94/100\n",
      "2s - loss: 0.2023 - acc: 0.9328\n",
      "Epoch 95/100\n",
      "3s - loss: 0.2027 - acc: 0.9328\n",
      "Epoch 96/100\n",
      "3s - loss: 0.2013 - acc: 0.9346\n",
      "Epoch 97/100\n",
      "2s - loss: 0.2015 - acc: 0.9337\n",
      "Epoch 98/100\n",
      "2s - loss: 0.2021 - acc: 0.9336\n",
      "Epoch 99/100\n",
      "2s - loss: 0.2011 - acc: 0.9343\n",
      "Epoch 100/100\n",
      "2s - loss: 0.2019 - acc: 0.9334\n",
      "Fold 1\n",
      "Epoch 1/100\n",
      "2s - loss: 0.9374 - acc: 0.6959\n",
      "Epoch 2/100\n",
      "2s - loss: 0.5002 - acc: 0.7753\n",
      "Epoch 3/100\n",
      "2s - loss: 0.4669 - acc: 0.7994\n",
      "Epoch 4/100\n",
      "2s - loss: 0.4296 - acc: 0.8209\n",
      "Epoch 5/100\n",
      "2s - loss: 0.4046 - acc: 0.8339\n",
      "Epoch 6/100\n",
      "3s - loss: 0.3888 - acc: 0.8423\n",
      "Epoch 7/100\n",
      "3s - loss: 0.3753 - acc: 0.8503\n",
      "Epoch 8/100\n",
      "2s - loss: 0.3581 - acc: 0.8586\n",
      "Epoch 9/100\n",
      "2s - loss: 0.3483 - acc: 0.8637\n",
      "Epoch 10/100\n",
      "2s - loss: 0.3375 - acc: 0.8695\n",
      "Epoch 11/100\n",
      "2s - loss: 0.3255 - acc: 0.8761\n",
      "Epoch 12/100\n",
      "2s - loss: 0.3163 - acc: 0.8805\n",
      "Epoch 13/100\n",
      "2s - loss: 0.3104 - acc: 0.8845\n",
      "Epoch 14/100\n",
      "2s - loss: 0.3025 - acc: 0.8883\n",
      "Epoch 15/100\n",
      "2s - loss: 0.2973 - acc: 0.8894\n",
      "Epoch 16/100\n",
      "2s - loss: 0.2904 - acc: 0.8934\n",
      "Epoch 17/100\n",
      "2s - loss: 0.2864 - acc: 0.8957\n",
      "Epoch 18/100\n",
      "2s - loss: 0.2807 - acc: 0.8978\n",
      "Epoch 19/100\n",
      "2s - loss: 0.2763 - acc: 0.9000\n",
      "Epoch 20/100\n",
      "2s - loss: 0.2710 - acc: 0.9022\n",
      "Epoch 21/100\n",
      "2s - loss: 0.2694 - acc: 0.9036\n",
      "Epoch 22/100\n",
      "2s - loss: 0.2665 - acc: 0.9047\n",
      "Epoch 23/100\n",
      "2s - loss: 0.2632 - acc: 0.9059\n",
      "Epoch 24/100\n",
      "2s - loss: 0.2585 - acc: 0.9082\n",
      "Epoch 25/100\n",
      "2s - loss: 0.2562 - acc: 0.9086\n",
      "Epoch 26/100\n",
      "2s - loss: 0.2540 - acc: 0.9096\n",
      "Epoch 27/100\n",
      "2s - loss: 0.2516 - acc: 0.9115\n",
      "Epoch 28/100\n",
      "2s - loss: 0.2487 - acc: 0.9123\n",
      "Epoch 29/100\n",
      "2s - loss: 0.2452 - acc: 0.9139\n",
      "Epoch 30/100\n",
      "2s - loss: 0.2432 - acc: 0.9141\n",
      "Epoch 31/100\n",
      "2s - loss: 0.2408 - acc: 0.9144\n",
      "Epoch 32/100\n",
      "2s - loss: 0.2398 - acc: 0.9153\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2374 - acc: 0.9172\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2369 - acc: 0.9171\n",
      "Epoch 35/100\n",
      "2s - loss: 0.2346 - acc: 0.9191\n",
      "Epoch 36/100\n",
      "2s - loss: 0.2321 - acc: 0.9193\n",
      "Epoch 37/100\n",
      "2s - loss: 0.2290 - acc: 0.9202\n",
      "Epoch 38/100\n",
      "2s - loss: 0.2289 - acc: 0.9212\n",
      "Epoch 39/100\n",
      "2s - loss: 0.2249 - acc: 0.9220\n",
      "Epoch 40/100\n",
      "2s - loss: 0.2232 - acc: 0.9230\n",
      "Epoch 41/100\n",
      "2s - loss: 0.2228 - acc: 0.9241\n",
      "Epoch 42/100\n",
      "2s - loss: 0.2184 - acc: 0.9257\n",
      "Epoch 43/100\n",
      "2s - loss: 0.2164 - acc: 0.9262\n",
      "Epoch 44/100\n",
      "2s - loss: 0.2143 - acc: 0.9267\n",
      "Epoch 45/100\n",
      "2s - loss: 0.2120 - acc: 0.9286\n",
      "Epoch 46/100\n",
      "2s - loss: 0.2089 - acc: 0.9298\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2080 - acc: 0.9306\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2063 - acc: 0.9315\n",
      "Epoch 49/100\n",
      "2s - loss: 0.2048 - acc: 0.9315\n",
      "Epoch 50/100\n",
      "2s - loss: 0.2021 - acc: 0.9325\n",
      "Epoch 51/100\n",
      "2s - loss: 0.2017 - acc: 0.9330\n",
      "Epoch 52/100\n",
      "2s - loss: 0.1982 - acc: 0.9344\n",
      "Epoch 53/100\n",
      "2s - loss: 0.1975 - acc: 0.9336\n",
      "Epoch 54/100\n",
      "2s - loss: 0.1958 - acc: 0.9346\n",
      "Epoch 55/100\n",
      "2s - loss: 0.1958 - acc: 0.9354\n",
      "Epoch 56/100\n",
      "2s - loss: 0.1945 - acc: 0.9359\n",
      "Epoch 57/100\n",
      "2s - loss: 0.1942 - acc: 0.9359\n",
      "Epoch 58/100\n",
      "2s - loss: 0.1933 - acc: 0.9364\n",
      "Epoch 59/100\n",
      "2s - loss: 0.1945 - acc: 0.9358\n",
      "Epoch 60/100\n",
      "2s - loss: 0.1914 - acc: 0.9372\n",
      "Epoch 61/100\n",
      "2s - loss: 0.1930 - acc: 0.9371\n",
      "Epoch 62/100\n",
      "2s - loss: 0.1915 - acc: 0.9371\n",
      "Epoch 63/100\n",
      "2s - loss: 0.1914 - acc: 0.9377\n",
      "Epoch 64/100\n",
      "2s - loss: 0.1905 - acc: 0.9381\n",
      "Epoch 65/100\n",
      "2s - loss: 0.1888 - acc: 0.9388\n",
      "Epoch 66/100\n",
      "2s - loss: 0.1894 - acc: 0.9390\n",
      "Epoch 67/100\n",
      "2s - loss: 0.1888 - acc: 0.9394\n",
      "Epoch 68/100\n",
      "2s - loss: 0.1879 - acc: 0.9398\n",
      "Epoch 69/100\n",
      "2s - loss: 0.1882 - acc: 0.9394\n",
      "Epoch 70/100\n",
      "2s - loss: 0.1870 - acc: 0.9398\n",
      "Epoch 71/100\n",
      "2s - loss: 0.1869 - acc: 0.9396\n",
      "Epoch 72/100\n",
      "2s - loss: 0.1867 - acc: 0.9400\n",
      "Epoch 73/100\n",
      "2s - loss: 0.1864 - acc: 0.9401\n",
      "Epoch 74/100\n",
      "2s - loss: 0.1866 - acc: 0.9397\n",
      "Epoch 75/100\n",
      "2s - loss: 0.1852 - acc: 0.9406\n",
      "Epoch 76/100\n",
      "2s - loss: 0.1841 - acc: 0.9407\n",
      "Epoch 77/100\n",
      "2s - loss: 0.1844 - acc: 0.9408\n",
      "Epoch 78/100\n",
      "2s - loss: 0.1854 - acc: 0.9414\n",
      "Epoch 79/100\n",
      "2s - loss: 0.1830 - acc: 0.9405\n",
      "Epoch 80/100\n",
      "2s - loss: 0.1827 - acc: 0.9409\n",
      "Epoch 81/100\n",
      "2s - loss: 0.1843 - acc: 0.9405\n",
      "Epoch 82/100\n",
      "2s - loss: 0.1831 - acc: 0.9415\n",
      "Epoch 83/100\n",
      "2s - loss: 0.1829 - acc: 0.9414\n",
      "Epoch 84/100\n",
      "2s - loss: 0.1825 - acc: 0.9423\n",
      "Epoch 85/100\n",
      "2s - loss: 0.1817 - acc: 0.9420\n",
      "Epoch 86/100\n",
      "2s - loss: 0.1824 - acc: 0.9420\n",
      "Epoch 87/100\n",
      "2s - loss: 0.1806 - acc: 0.9424\n",
      "Epoch 88/100\n",
      "2s - loss: 0.1840 - acc: 0.9417\n",
      "Epoch 89/100\n",
      "2s - loss: 0.1834 - acc: 0.9412\n",
      "Epoch 90/100\n",
      "2s - loss: 0.1819 - acc: 0.9417\n",
      "Epoch 91/100\n",
      "2s - loss: 0.1815 - acc: 0.9418\n",
      "Epoch 92/100\n",
      "2s - loss: 0.1815 - acc: 0.9427\n",
      "Epoch 93/100\n",
      "2s - loss: 0.1810 - acc: 0.9420\n",
      "Epoch 94/100\n",
      "2s - loss: 0.1805 - acc: 0.9428\n",
      "Epoch 95/100\n",
      "2s - loss: 0.1815 - acc: 0.9424\n",
      "Epoch 96/100\n",
      "2s - loss: 0.1802 - acc: 0.9436\n",
      "Epoch 97/100\n",
      "2s - loss: 0.1793 - acc: 0.9435\n",
      "Epoch 98/100\n",
      "2s - loss: 0.1793 - acc: 0.9436\n",
      "Epoch 99/100\n",
      "2s - loss: 0.1805 - acc: 0.9429\n",
      "Epoch 100/100\n",
      "2s - loss: 0.1801 - acc: 0.9431\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "2s - loss: 1.5245 - acc: 0.6902\n",
      "Epoch 2/100\n",
      "2s - loss: 0.8828 - acc: 0.7271\n",
      "Epoch 3/100\n",
      "2s - loss: 0.4941 - acc: 0.7582\n",
      "Epoch 4/100\n",
      "2s - loss: 0.4678 - acc: 0.7796\n",
      "Epoch 5/100\n",
      "2s - loss: 0.4488 - acc: 0.7945\n",
      "Epoch 6/100\n",
      "2s - loss: 0.4318 - acc: 0.8056\n",
      "Epoch 7/100\n",
      "2s - loss: 0.4261 - acc: 0.8101\n",
      "Epoch 8/100\n",
      "2s - loss: 0.4173 - acc: 0.8153\n",
      "Epoch 9/100\n",
      "2s - loss: 0.4062 - acc: 0.8221\n",
      "Epoch 10/100\n",
      "2s - loss: 0.3970 - acc: 0.8322\n",
      "Epoch 11/100\n",
      "2s - loss: 0.3885 - acc: 0.8376\n",
      "Epoch 12/100\n",
      "2s - loss: 0.3814 - acc: 0.8422\n",
      "Epoch 13/100\n",
      "2s - loss: 0.3787 - acc: 0.8439\n",
      "Epoch 14/100\n",
      "2s - loss: 0.3715 - acc: 0.8480\n",
      "Epoch 15/100\n",
      "2s - loss: 0.3633 - acc: 0.8539\n",
      "Epoch 16/100\n",
      "2s - loss: 0.3555 - acc: 0.8572\n",
      "Epoch 17/100\n",
      "2s - loss: 0.3486 - acc: 0.8613\n",
      "Epoch 18/100\n",
      "2s - loss: 0.3412 - acc: 0.8643\n",
      "Epoch 19/100\n",
      "2s - loss: 0.3370 - acc: 0.8668\n",
      "Epoch 20/100\n",
      "2s - loss: 0.3397 - acc: 0.8664\n",
      "Epoch 21/100\n",
      "2s - loss: 0.3292 - acc: 0.8702\n",
      "Epoch 22/100\n",
      "2s - loss: 0.3289 - acc: 0.8716\n",
      "Epoch 23/100\n",
      "2s - loss: 0.3259 - acc: 0.8733\n",
      "Epoch 24/100\n",
      "2s - loss: 0.3212 - acc: 0.8759\n",
      "Epoch 25/100\n",
      "2s - loss: 0.3221 - acc: 0.8755\n",
      "Epoch 26/100\n",
      "2s - loss: 0.3173 - acc: 0.8786\n",
      "Epoch 27/100\n",
      "3s - loss: 0.3140 - acc: 0.8801\n",
      "Epoch 28/100\n",
      "2s - loss: 0.3087 - acc: 0.8833\n",
      "Epoch 29/100\n",
      "2s - loss: 0.3064 - acc: 0.8848\n",
      "Epoch 30/100\n",
      "2s - loss: 0.3076 - acc: 0.8841\n",
      "Epoch 31/100\n",
      "2s - loss: 0.2991 - acc: 0.8880\n",
      "Epoch 32/100\n",
      "2s - loss: 0.2972 - acc: 0.8875\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2947 - acc: 0.8894\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2905 - acc: 0.8915\n",
      "Epoch 35/100\n",
      "2s - loss: 0.2893 - acc: 0.8918\n",
      "Epoch 36/100\n",
      "2s - loss: 0.2863 - acc: 0.8933\n",
      "Epoch 37/100\n",
      "2s - loss: 0.2829 - acc: 0.8953\n",
      "Epoch 38/100\n",
      "2s - loss: 0.2791 - acc: 0.8965\n",
      "Epoch 39/100\n",
      "2s - loss: 0.2779 - acc: 0.8974\n",
      "Epoch 40/100\n",
      "2s - loss: 0.2741 - acc: 0.8996\n",
      "Epoch 41/100\n",
      "2s - loss: 0.2722 - acc: 0.9003\n",
      "Epoch 42/100\n",
      "2s - loss: 0.2685 - acc: 0.9021\n",
      "Epoch 43/100\n",
      "2s - loss: 0.2660 - acc: 0.9025\n",
      "Epoch 44/100\n",
      "2s - loss: 0.2649 - acc: 0.9034\n",
      "Epoch 45/100\n",
      "2s - loss: 0.2610 - acc: 0.9049\n",
      "Epoch 46/100\n",
      "2s - loss: 0.2585 - acc: 0.9067\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2602 - acc: 0.9067\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2555 - acc: 0.9087\n",
      "Epoch 49/100\n",
      "2s - loss: 0.2539 - acc: 0.9104\n",
      "Epoch 50/100\n",
      "2s - loss: 0.2494 - acc: 0.9111\n",
      "Epoch 51/100\n",
      "2s - loss: 0.2476 - acc: 0.9115\n",
      "Epoch 52/100\n",
      "2s - loss: 0.2468 - acc: 0.9127\n",
      "Epoch 53/100\n",
      "2s - loss: 0.2445 - acc: 0.9136\n",
      "Epoch 54/100\n",
      "2s - loss: 0.2463 - acc: 0.9131\n",
      "Epoch 55/100\n",
      "2s - loss: 0.2406 - acc: 0.9152\n",
      "Epoch 56/100\n",
      "2s - loss: 0.2388 - acc: 0.9162\n",
      "Epoch 57/100\n",
      "2s - loss: 0.2389 - acc: 0.9157\n",
      "Epoch 58/100\n",
      "2s - loss: 0.2374 - acc: 0.9164\n",
      "Epoch 59/100\n",
      "2s - loss: 0.2369 - acc: 0.9174\n",
      "Epoch 60/100\n",
      "2s - loss: 0.2353 - acc: 0.9177\n",
      "Epoch 61/100\n",
      "2s - loss: 0.2330 - acc: 0.9187\n",
      "Epoch 62/100\n",
      "2s - loss: 0.2329 - acc: 0.9179\n",
      "Epoch 63/100\n",
      "2s - loss: 0.2325 - acc: 0.9190\n",
      "Epoch 64/100\n",
      "2s - loss: 0.2281 - acc: 0.9207\n",
      "Epoch 65/100\n",
      "2s - loss: 0.2280 - acc: 0.9214\n",
      "Epoch 66/100\n",
      "2s - loss: 0.2261 - acc: 0.9202\n",
      "Epoch 67/100\n",
      "2s - loss: 0.2318 - acc: 0.9194\n",
      "Epoch 68/100\n",
      "2s - loss: 0.2283 - acc: 0.9206\n",
      "Epoch 69/100\n",
      "2s - loss: 0.2238 - acc: 0.9223\n",
      "Epoch 70/100\n",
      "2s - loss: 0.2243 - acc: 0.9221\n",
      "Epoch 71/100\n",
      "2s - loss: 0.2221 - acc: 0.9221\n",
      "Epoch 72/100\n",
      "2s - loss: 0.2254 - acc: 0.9217\n",
      "Epoch 73/100\n",
      "2s - loss: 0.2208 - acc: 0.9229\n",
      "Epoch 74/100\n",
      "2s - loss: 0.2180 - acc: 0.9243\n",
      "Epoch 75/100\n",
      "2s - loss: 0.2186 - acc: 0.9237\n",
      "Epoch 76/100\n",
      "2s - loss: 0.2210 - acc: 0.9230\n",
      "Epoch 77/100\n",
      "2s - loss: 0.2214 - acc: 0.9233\n",
      "Epoch 78/100\n",
      "2s - loss: 0.2182 - acc: 0.9244\n",
      "Epoch 79/100\n",
      "2s - loss: 0.2159 - acc: 0.9247\n",
      "Epoch 80/100\n",
      "2s - loss: 0.2158 - acc: 0.9251\n",
      "Epoch 81/100\n",
      "2s - loss: 0.2155 - acc: 0.9260\n",
      "Epoch 82/100\n",
      "2s - loss: 0.2164 - acc: 0.9246\n",
      "Epoch 83/100\n",
      "2s - loss: 0.2164 - acc: 0.9258\n",
      "Epoch 84/100\n",
      "2s - loss: 0.2142 - acc: 0.9260\n",
      "Epoch 85/100\n",
      "2s - loss: 0.2140 - acc: 0.9269\n",
      "Epoch 86/100\n",
      "2s - loss: 0.2147 - acc: 0.9268\n",
      "Epoch 87/100\n",
      "2s - loss: 0.2169 - acc: 0.9255\n",
      "Epoch 88/100\n",
      "2s - loss: 0.2165 - acc: 0.9264\n",
      "Epoch 89/100\n",
      "2s - loss: 0.2143 - acc: 0.9269\n",
      "Epoch 90/100\n",
      "2s - loss: 0.2158 - acc: 0.9269\n",
      "Epoch 91/100\n",
      "2s - loss: 0.2173 - acc: 0.9256\n",
      "Epoch 92/100\n",
      "2s - loss: 0.2122 - acc: 0.9284\n",
      "Epoch 93/100\n",
      "2s - loss: 0.2114 - acc: 0.9277\n",
      "Epoch 94/100\n",
      "2s - loss: 0.2086 - acc: 0.9289\n",
      "Epoch 95/100\n",
      "2s - loss: 0.2102 - acc: 0.9276\n",
      "Epoch 96/100\n",
      "2s - loss: 0.2079 - acc: 0.9295\n",
      "Epoch 97/100\n",
      "2s - loss: 0.2079 - acc: 0.9297\n",
      "Epoch 98/100\n",
      "2s - loss: 0.2080 - acc: 0.9290\n",
      "Epoch 99/100\n",
      "2s - loss: 0.2093 - acc: 0.9283\n",
      "Epoch 100/100\n",
      "2s - loss: 0.2041 - acc: 0.9291\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "2s - loss: 1.7526 - acc: 0.6844\n",
      "Epoch 2/100\n",
      "2s - loss: 0.6467 - acc: 0.7400\n",
      "Epoch 3/100\n",
      "2s - loss: 0.5210 - acc: 0.7626\n",
      "Epoch 4/100\n",
      "2s - loss: 0.4703 - acc: 0.7820\n",
      "Epoch 5/100\n",
      "2s - loss: 0.4496 - acc: 0.7945\n",
      "Epoch 6/100\n",
      "2s - loss: 0.4370 - acc: 0.8011\n",
      "Epoch 7/100\n",
      "2s - loss: 0.4249 - acc: 0.8129\n",
      "Epoch 8/100\n",
      "2s - loss: 0.4155 - acc: 0.8192\n",
      "Epoch 9/100\n",
      "2s - loss: 0.3999 - acc: 0.8268\n",
      "Epoch 10/100\n",
      "2s - loss: 0.3832 - acc: 0.8365\n",
      "Epoch 11/100\n",
      "2s - loss: 0.3798 - acc: 0.8355\n",
      "Epoch 12/100\n",
      "2s - loss: 0.3635 - acc: 0.8469\n",
      "Epoch 13/100\n",
      "2s - loss: 0.3468 - acc: 0.8591\n",
      "Epoch 14/100\n",
      "2s - loss: 0.3382 - acc: 0.8656\n",
      "Epoch 15/100\n",
      "2s - loss: 0.3268 - acc: 0.8710\n",
      "Epoch 16/100\n",
      "2s - loss: 0.3173 - acc: 0.8751\n",
      "Epoch 17/100\n",
      "2s - loss: 0.3164 - acc: 0.8777\n",
      "Epoch 18/100\n",
      "2s - loss: 0.3058 - acc: 0.8825\n",
      "Epoch 19/100\n",
      "2s - loss: 0.3028 - acc: 0.8846\n",
      "Epoch 20/100\n",
      "2s - loss: 0.2969 - acc: 0.8862\n",
      "Epoch 21/100\n",
      "2s - loss: 0.2927 - acc: 0.8882\n",
      "Epoch 22/100\n",
      "2s - loss: 0.2886 - acc: 0.8914\n",
      "Epoch 23/100\n",
      "2s - loss: 0.2826 - acc: 0.8935\n",
      "Epoch 24/100\n",
      "2s - loss: 0.2787 - acc: 0.8951\n",
      "Epoch 25/100\n",
      "2s - loss: 0.2712 - acc: 0.8977\n",
      "Epoch 26/100\n",
      "2s - loss: 0.2692 - acc: 0.8998\n",
      "Epoch 27/100\n",
      "2s - loss: 0.2668 - acc: 0.9004\n",
      "Epoch 28/100\n",
      "2s - loss: 0.2625 - acc: 0.9032\n",
      "Epoch 29/100\n",
      "2s - loss: 0.2590 - acc: 0.9042\n",
      "Epoch 30/100\n",
      "2s - loss: 0.2573 - acc: 0.9051\n",
      "Epoch 31/100\n",
      "2s - loss: 0.2539 - acc: 0.9072\n",
      "Epoch 32/100\n",
      "2s - loss: 0.2512 - acc: 0.9080\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2502 - acc: 0.9085\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2480 - acc: 0.9104\n",
      "Epoch 35/100\n",
      "2s - loss: 0.2435 - acc: 0.9118\n",
      "Epoch 36/100\n",
      "2s - loss: 0.2416 - acc: 0.9126\n",
      "Epoch 37/100\n",
      "2s - loss: 0.2411 - acc: 0.9124\n",
      "Epoch 38/100\n",
      "2s - loss: 0.2403 - acc: 0.9131\n",
      "Epoch 39/100\n",
      "2s - loss: 0.2365 - acc: 0.9145\n",
      "Epoch 40/100\n",
      "2s - loss: 0.2360 - acc: 0.9152\n",
      "Epoch 41/100\n",
      "2s - loss: 0.2353 - acc: 0.9157\n",
      "Epoch 42/100\n",
      "2s - loss: 0.2333 - acc: 0.9162\n",
      "Epoch 43/100\n",
      "2s - loss: 0.2327 - acc: 0.9163\n",
      "Epoch 44/100\n",
      "2s - loss: 0.2332 - acc: 0.9169\n",
      "Epoch 45/100\n",
      "2s - loss: 0.2323 - acc: 0.9164\n",
      "Epoch 46/100\n",
      "2s - loss: 0.2297 - acc: 0.9176\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2307 - acc: 0.9178\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2299 - acc: 0.9181\n",
      "Epoch 49/100\n",
      "2s - loss: 0.2288 - acc: 0.9185\n",
      "Epoch 50/100\n",
      "2s - loss: 0.2313 - acc: 0.9181\n",
      "Epoch 51/100\n",
      "2s - loss: 0.2260 - acc: 0.9189\n",
      "Epoch 52/100\n",
      "2s - loss: 0.2237 - acc: 0.9193\n",
      "Epoch 53/100\n",
      "2s - loss: 0.2240 - acc: 0.9205\n",
      "Epoch 54/100\n",
      "2s - loss: 0.2233 - acc: 0.9201\n",
      "Epoch 55/100\n",
      "2s - loss: 0.2224 - acc: 0.9204\n",
      "Epoch 56/100\n",
      "2s - loss: 0.2220 - acc: 0.9210\n",
      "Epoch 57/100\n",
      "2s - loss: 0.2218 - acc: 0.9208\n",
      "Epoch 58/100\n",
      "2s - loss: 0.2243 - acc: 0.9203\n",
      "Epoch 59/100\n",
      "2s - loss: 0.2215 - acc: 0.9216\n",
      "Epoch 60/100\n",
      "2s - loss: 0.2213 - acc: 0.9214\n",
      "Epoch 61/100\n",
      "2s - loss: 0.2198 - acc: 0.9214\n",
      "Epoch 62/100\n",
      "2s - loss: 0.2204 - acc: 0.9214\n",
      "Epoch 63/100\n",
      "2s - loss: 0.2190 - acc: 0.9219\n",
      "Epoch 64/100\n",
      "2s - loss: 0.2194 - acc: 0.9211\n",
      "Epoch 65/100\n",
      "2s - loss: 0.2173 - acc: 0.9217\n",
      "Epoch 66/100\n",
      "2s - loss: 0.2195 - acc: 0.9218\n",
      "Epoch 67/100\n",
      "2s - loss: 0.2172 - acc: 0.9232\n",
      "Epoch 68/100\n",
      "2s - loss: 0.2171 - acc: 0.9229\n",
      "Epoch 69/100\n",
      "2s - loss: 0.2158 - acc: 0.9242\n",
      "Epoch 70/100\n",
      "2s - loss: 0.2162 - acc: 0.9237\n",
      "Epoch 71/100\n",
      "2s - loss: 0.2176 - acc: 0.9234\n",
      "Epoch 72/100\n",
      "2s - loss: 0.2154 - acc: 0.9227\n",
      "Epoch 73/100\n",
      "2s - loss: 0.2154 - acc: 0.9239\n",
      "Epoch 74/100\n",
      "2s - loss: 0.2185 - acc: 0.9241\n",
      "Epoch 75/100\n",
      "2s - loss: 0.2161 - acc: 0.9247\n",
      "Epoch 76/100\n",
      "2s - loss: 0.2170 - acc: 0.9246\n",
      "Epoch 77/100\n",
      "2s - loss: 0.2196 - acc: 0.9240\n",
      "Epoch 78/100\n",
      "2s - loss: 0.2163 - acc: 0.9253\n",
      "Epoch 79/100\n",
      "2s - loss: 0.2185 - acc: 0.9237\n",
      "Epoch 80/100\n",
      "2s - loss: 0.2161 - acc: 0.9249\n",
      "Epoch 81/100\n",
      "2s - loss: 0.2167 - acc: 0.9245\n",
      "Epoch 82/100\n",
      "2s - loss: 0.2158 - acc: 0.9252\n",
      "Epoch 83/100\n",
      "2s - loss: 0.2140 - acc: 0.9245\n",
      "Epoch 84/100\n",
      "2s - loss: 0.2140 - acc: 0.9252\n",
      "Epoch 85/100\n",
      "2s - loss: 0.2122 - acc: 0.9273\n",
      "Epoch 86/100\n",
      "2s - loss: 0.2128 - acc: 0.9260\n",
      "Epoch 87/100\n",
      "2s - loss: 0.2113 - acc: 0.9262\n",
      "Epoch 88/100\n",
      "2s - loss: 0.2119 - acc: 0.9264\n",
      "Epoch 89/100\n",
      "2s - loss: 0.2104 - acc: 0.9276\n",
      "Epoch 90/100\n",
      "2s - loss: 0.2107 - acc: 0.9265\n",
      "Epoch 91/100\n",
      "2s - loss: 0.2106 - acc: 0.9280\n",
      "Epoch 92/100\n",
      "2s - loss: 0.2105 - acc: 0.9272\n",
      "Epoch 93/100\n",
      "2s - loss: 0.2124 - acc: 0.9266\n",
      "Epoch 94/100\n",
      "2s - loss: 0.2092 - acc: 0.9280\n",
      "Epoch 95/100\n",
      "2s - loss: 0.2106 - acc: 0.9276\n",
      "Epoch 96/100\n",
      "2s - loss: 0.2098 - acc: 0.9280\n",
      "Epoch 97/100\n",
      "2s - loss: 0.2083 - acc: 0.9278\n",
      "Epoch 98/100\n",
      "2s - loss: 0.2081 - acc: 0.9292\n",
      "Epoch 99/100\n",
      "2s - loss: 0.2075 - acc: 0.9286\n",
      "Epoch 100/100\n",
      "2s - loss: 0.2093 - acc: 0.9286\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "2s - loss: 0.6876 - acc: 0.6875\n",
      "Epoch 2/100\n",
      "2s - loss: 0.4974 - acc: 0.7755\n",
      "Epoch 3/100\n",
      "2s - loss: 0.4450 - acc: 0.8067\n",
      "Epoch 4/100\n",
      "2s - loss: 0.4169 - acc: 0.8218\n",
      "Epoch 5/100\n",
      "2s - loss: 0.4024 - acc: 0.8270\n",
      "Epoch 6/100\n",
      "2s - loss: 0.3901 - acc: 0.8326\n",
      "Epoch 7/100\n",
      "2s - loss: 0.3790 - acc: 0.8370\n",
      "Epoch 8/100\n",
      "2s - loss: 0.3683 - acc: 0.8456\n",
      "Epoch 9/100\n",
      "2s - loss: 0.3596 - acc: 0.8547\n",
      "Epoch 10/100\n",
      "2s - loss: 0.3484 - acc: 0.8603\n",
      "Epoch 11/100\n",
      "2s - loss: 0.3409 - acc: 0.8638\n",
      "Epoch 12/100\n",
      "2s - loss: 0.3343 - acc: 0.8688\n",
      "Epoch 13/100\n",
      "2s - loss: 0.3286 - acc: 0.8699\n",
      "Epoch 14/100\n",
      "2s - loss: 0.3227 - acc: 0.8737\n",
      "Epoch 15/100\n",
      "2s - loss: 0.3196 - acc: 0.8750\n",
      "Epoch 16/100\n",
      "2s - loss: 0.3160 - acc: 0.8765\n",
      "Epoch 17/100\n",
      "2s - loss: 0.3105 - acc: 0.8789\n",
      "Epoch 18/100\n",
      "2s - loss: 0.3072 - acc: 0.8809\n",
      "Epoch 19/100\n",
      "2s - loss: 0.3002 - acc: 0.8846\n",
      "Epoch 20/100\n",
      "2s - loss: 0.2960 - acc: 0.8864\n",
      "Epoch 21/100\n",
      "2s - loss: 0.3050 - acc: 0.8821\n",
      "Epoch 22/100\n",
      "2s - loss: 0.2906 - acc: 0.8894\n",
      "Epoch 23/100\n",
      "2s - loss: 0.2856 - acc: 0.8923\n",
      "Epoch 24/100\n",
      "2s - loss: 0.2825 - acc: 0.8931\n",
      "Epoch 25/100\n",
      "2s - loss: 0.2810 - acc: 0.8955\n",
      "Epoch 26/100\n",
      "2s - loss: 0.2791 - acc: 0.8956\n",
      "Epoch 27/100\n",
      "2s - loss: 0.2780 - acc: 0.8963\n",
      "Epoch 28/100\n",
      "2s - loss: 0.2741 - acc: 0.8984\n",
      "Epoch 29/100\n",
      "2s - loss: 0.2751 - acc: 0.8982\n",
      "Epoch 30/100\n",
      "2s - loss: 0.2723 - acc: 0.8981\n",
      "Epoch 31/100\n",
      "2s - loss: 0.2707 - acc: 0.9001\n",
      "Epoch 32/100\n",
      "2s - loss: 0.2682 - acc: 0.9008\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2669 - acc: 0.9027\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2624 - acc: 0.9035\n",
      "Epoch 35/100\n",
      "2s - loss: 0.2630 - acc: 0.9030\n",
      "Epoch 36/100\n",
      "2s - loss: 0.2582 - acc: 0.9050\n",
      "Epoch 37/100\n",
      "2s - loss: 0.2566 - acc: 0.9068\n",
      "Epoch 38/100\n",
      "2s - loss: 0.2566 - acc: 0.9076\n",
      "Epoch 39/100\n",
      "2s - loss: 0.2534 - acc: 0.9087\n",
      "Epoch 40/100\n",
      "2s - loss: 0.2513 - acc: 0.9103\n",
      "Epoch 41/100\n",
      "2s - loss: 0.2499 - acc: 0.9096\n",
      "Epoch 42/100\n",
      "2s - loss: 0.2498 - acc: 0.9101\n",
      "Epoch 43/100\n",
      "2s - loss: 0.2459 - acc: 0.9115\n",
      "Epoch 44/100\n",
      "2s - loss: 0.2451 - acc: 0.9120\n",
      "Epoch 45/100\n",
      "2s - loss: 0.2430 - acc: 0.9139\n",
      "Epoch 46/100\n",
      "2s - loss: 0.2428 - acc: 0.9137\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2393 - acc: 0.9151\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2386 - acc: 0.9154\n",
      "Epoch 49/100\n",
      "2s - loss: 0.2350 - acc: 0.9165\n",
      "Epoch 50/100\n",
      "2s - loss: 0.2361 - acc: 0.9158\n",
      "Epoch 51/100\n",
      "2s - loss: 0.2324 - acc: 0.9179\n",
      "Epoch 52/100\n",
      "2s - loss: 0.2320 - acc: 0.9178\n",
      "Epoch 53/100\n",
      "2s - loss: 0.2295 - acc: 0.9191\n",
      "Epoch 54/100\n",
      "2s - loss: 0.2283 - acc: 0.9199\n",
      "Epoch 55/100\n",
      "2s - loss: 0.2274 - acc: 0.9208\n",
      "Epoch 56/100\n",
      "2s - loss: 0.2266 - acc: 0.9205\n",
      "Epoch 57/100\n",
      "2s - loss: 0.2270 - acc: 0.9208\n",
      "Epoch 58/100\n",
      "2s - loss: 0.2252 - acc: 0.9211\n",
      "Epoch 59/100\n",
      "2s - loss: 0.2229 - acc: 0.9221\n",
      "Epoch 60/100\n",
      "2s - loss: 0.2229 - acc: 0.9226\n",
      "Epoch 61/100\n",
      "2s - loss: 0.2219 - acc: 0.9234\n",
      "Epoch 62/100\n",
      "2s - loss: 0.2210 - acc: 0.9238\n",
      "Epoch 63/100\n",
      "2s - loss: 0.2207 - acc: 0.9242\n",
      "Epoch 64/100\n",
      "2s - loss: 0.2196 - acc: 0.9239\n",
      "Epoch 65/100\n",
      "2s - loss: 0.2173 - acc: 0.9254\n",
      "Epoch 66/100\n",
      "2s - loss: 0.2192 - acc: 0.9248\n",
      "Epoch 67/100\n",
      "2s - loss: 0.2179 - acc: 0.9251\n",
      "Epoch 68/100\n",
      "2s - loss: 0.2172 - acc: 0.9250\n",
      "Epoch 69/100\n",
      "2s - loss: 0.2155 - acc: 0.9251\n",
      "Epoch 70/100\n",
      "2s - loss: 0.2158 - acc: 0.9258\n",
      "Epoch 71/100\n",
      "2s - loss: 0.2141 - acc: 0.9264\n",
      "Epoch 72/100\n",
      "2s - loss: 0.2130 - acc: 0.9265\n",
      "Epoch 73/100\n",
      "2s - loss: 0.2138 - acc: 0.9260\n",
      "Epoch 74/100\n",
      "2s - loss: 0.2129 - acc: 0.9261\n",
      "Epoch 75/100\n",
      "2s - loss: 0.2112 - acc: 0.9269\n",
      "Epoch 76/100\n",
      "2s - loss: 0.2103 - acc: 0.9265\n",
      "Epoch 77/100\n",
      "2s - loss: 0.2088 - acc: 0.9278\n",
      "Epoch 78/100\n",
      "2s - loss: 0.2120 - acc: 0.9272\n",
      "Epoch 79/100\n",
      "2s - loss: 0.2098 - acc: 0.9282\n",
      "Epoch 80/100\n",
      "2s - loss: 0.2080 - acc: 0.9287\n",
      "Epoch 81/100\n",
      "2s - loss: 0.2078 - acc: 0.9284\n",
      "Epoch 82/100\n",
      "2s - loss: 0.2059 - acc: 0.9295\n",
      "Epoch 83/100\n",
      "2s - loss: 0.2067 - acc: 0.9287\n",
      "Epoch 84/100\n",
      "2s - loss: 0.2040 - acc: 0.9299\n",
      "Epoch 85/100\n",
      "2s - loss: 0.2022 - acc: 0.9316\n",
      "Epoch 86/100\n",
      "2s - loss: 0.2045 - acc: 0.9296\n",
      "Epoch 87/100\n",
      "2s - loss: 0.2020 - acc: 0.9317\n",
      "Epoch 88/100\n",
      "2s - loss: 0.2011 - acc: 0.9324\n",
      "Epoch 89/100\n",
      "2s - loss: 0.2018 - acc: 0.9318\n",
      "Epoch 90/100\n",
      "2s - loss: 0.2010 - acc: 0.9328\n",
      "Epoch 91/100\n",
      "2s - loss: 0.1986 - acc: 0.9338\n",
      "Epoch 92/100\n",
      "2s - loss: 0.1994 - acc: 0.9336\n",
      "Epoch 93/100\n",
      "2s - loss: 0.1985 - acc: 0.9341\n",
      "Epoch 94/100\n",
      "2s - loss: 0.1964 - acc: 0.9345\n",
      "Epoch 95/100\n",
      "2s - loss: 0.1964 - acc: 0.9345\n",
      "Epoch 96/100\n",
      "2s - loss: 0.1972 - acc: 0.9345\n",
      "Epoch 97/100\n",
      "2s - loss: 0.1986 - acc: 0.9339\n",
      "Epoch 98/100\n",
      "2s - loss: 0.1968 - acc: 0.9349\n",
      "Epoch 99/100\n",
      "2s - loss: 0.1986 - acc: 0.9349\n",
      "Epoch 100/100\n",
      "2s - loss: 0.1952 - acc: 0.9348\n",
      "Blending.\n"
     ]
    }
   ],
   "source": [
    "y_submission = blend.fit_predict(X.values, y.values, X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99737840091243846"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99801121215983213"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
